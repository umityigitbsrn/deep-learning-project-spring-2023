{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "from numpy.random import binomial\n",
    "from numpy.random import choice\n",
    "\n",
    "import gym\n",
    "import datetime\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "Transitions = namedtuple('Transitions', ['obs', 'action', 'reward', 'next_obs', 'done'])\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, config):\n",
    "        replay_buffer_size = config['replay_buffer_size']\n",
    "        seed = config['seed']\n",
    "        nr.seed(seed)\n",
    "\n",
    "        self.replay_buffer_size = replay_buffer_size\n",
    "        self.obs = deque([], maxlen=self.replay_buffer_size)\n",
    "        self.action = deque([], maxlen=self.replay_buffer_size)\n",
    "        self.reward = deque([], maxlen=self.replay_buffer_size)\n",
    "        self.next_obs = deque([], maxlen=self.replay_buffer_size)\n",
    "        self.done = deque([], maxlen=self.replay_buffer_size)\n",
    "\n",
    "    def append_memory(self,\n",
    "                      obs,\n",
    "                      action,\n",
    "                      reward,\n",
    "                      next_obs,\n",
    "                      done: bool):\n",
    "        self.obs.append(obs)\n",
    "        self.action.append(action)\n",
    "        self.reward.append(reward)\n",
    "        self.next_obs.append(next_obs)\n",
    "        self.done.append(done)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        buffer_size = len(self.obs)\n",
    "\n",
    "        idx = nr.choice(buffer_size,\n",
    "                        size=min(buffer_size, batch_size),\n",
    "                        replace=False)\n",
    "        t = Transitions\n",
    "        t.obs = torch.stack(list(map(self.obs.__getitem__, idx)))\n",
    "        t.action = torch.stack(list(map(self.action.__getitem__, idx)))\n",
    "        t.reward = torch.stack(list(map(self.reward.__getitem__, idx)))\n",
    "        t.next_obs = torch.stack(list(map(self.next_obs.__getitem__, idx)))\n",
    "        t.done = torch.tensor(list(map(self.done.__getitem__, idx)))[:, None]\n",
    "        return t\n",
    "\n",
    "    def clear(self):\n",
    "        self.obs = deque([], maxlen=self.replay_buffer_size)\n",
    "        self.action = deque([], maxlen=self.replay_buffer_size)\n",
    "        self.reward = deque([], maxlen=self.replay_buffer_size)\n",
    "        self.next_obs = deque([], maxlen=self.replay_buffer_size)\n",
    "        self.done = deque([], maxlen=self.replay_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.DoubleTensor\n",
    "torch.set_default_tensor_type(Tensor)\n",
    "\n",
    "\n",
    "class DQN:\n",
    "    def __init__(self, config):\n",
    "\n",
    "        torch.manual_seed(config['seed'])\n",
    "\n",
    "        self.lr = config['lr']  # learning rate\n",
    "        self.C = config['C']  # copy steps\n",
    "        self.eps_len = config['eps_len']  # length of epsilon greedy exploration\n",
    "        self.eps_max = config['eps_max']\n",
    "        self.eps_min = config['eps_min']\n",
    "        self.discount = config['discount']  # discount factor\n",
    "        self.batch_size = config['batch_size']  # mini batch size\n",
    "\n",
    "        self.dims_hidden_neurons = config['dims_hidden_neurons']\n",
    "        self.dim_obs = config['dim_obs']\n",
    "        self.dim_action = config['dim_action']\n",
    "\n",
    "        self.Q = QNetwork(dim_obs=self.dim_obs,\n",
    "                          dim_action=self.dim_action,\n",
    "                          dims_hidden_neurons=self.dims_hidden_neurons)\n",
    "        self.Q_tar = QNetwork(dim_obs=self.dim_obs,\n",
    "                              dim_action=self.dim_action,\n",
    "                              dims_hidden_neurons=self.dims_hidden_neurons)\n",
    "\n",
    "        self.optimizer_Q = torch.optim.Adam(self.Q.parameters(), lr=self.lr)\n",
    "        self.training_step = 0\n",
    "\n",
    "    def update(self, buffer):\n",
    "        t = buffer.sample(self.batch_size)\n",
    "\n",
    "        s = t.obs\n",
    "        a = t.action\n",
    "        r = t.reward\n",
    "        sp = t.next_obs\n",
    "        done = t.done\n",
    "\n",
    "        self.training_step += 1\n",
    "\n",
    "        # the actual size of the batch in curent step\n",
    "        b_size = len(s)\n",
    "        # the list to save bacth Q and target_Q\n",
    "        Q_values = torch.empty((b_size, 1))\n",
    "        target_values = torch.empty((b_size, 1))\n",
    "\n",
    "        for i in range(b_size):\n",
    "            actions_values = self.Q.forward(s[i])\n",
    "            action = a[i][0]\n",
    "            # compute target values considering the terminal condition\n",
    "            if done[i][0] == True:\n",
    "                with torch.no_grad():\n",
    "                    target_values[i] = r[i][0]\n",
    "            else:\n",
    "                next_actions_values = self.Q_tar.forward(sp[i])\n",
    "                max_action_value = max(next_actions_values)\n",
    "                with torch.no_grad():\n",
    "                    target_values[i] = r[i][0] + self.discount * max_action_value\n",
    "            # assign Q value from the batch\n",
    "            Q_values[i] = actions_values[action]\n",
    "\n",
    "        # compute the MSE loss\n",
    "        loss = nn.functional.mse_loss(Q_values, target_values)\n",
    "        self.optimizer_Q.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer_Q.step()\n",
    "        \n",
    "        # for update target Q-network every C update steps\n",
    "        if self.training_step % self.C == 0:\n",
    "            update_param = self.Q.state_dict()\n",
    "            self.Q_tar.load_state_dict(update_param)\n",
    "\n",
    "\n",
    "    def act_operate(self, observation: torch.Tensor):\n",
    "        # epsilon greedy:\n",
    "        first_term = self.eps_max * (self.eps_len - self.training_step) / self.eps_len\n",
    "        eps = max(first_term, self.eps_min)\n",
    "\n",
    "        explore = binomial(1, eps)\n",
    "\n",
    "        if explore == 1:\n",
    "            a = choice(self.dim_action)\n",
    "        else:\n",
    "            self.Q.eval()\n",
    "            Q = self.Q(observation)\n",
    "            val, a = torch.max(Q, axis=1)\n",
    "            a = a.item()\n",
    "            self.Q.train()\n",
    "        return a\n",
    "\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim_obs: int,\n",
    "                 dim_action: int,\n",
    "                 dims_hidden_neurons: Tuple[int] = (64, 64)):\n",
    "        if not isinstance(dim_obs, int):\n",
    "            TypeError('dimension of observation must be int')\n",
    "        if not isinstance(dim_action, int):\n",
    "            TypeError('dimension of action must be int')\n",
    "        if not isinstance(dims_hidden_neurons, tuple):\n",
    "            TypeError('dimensions of hidden neurons must be tuple of int')\n",
    "\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.num_layers = len(dims_hidden_neurons)\n",
    "        self.dim_action = dim_action\n",
    "\n",
    "        n_neurons = (dim_obs, ) + dims_hidden_neurons + (dim_action, )\n",
    "        for i, (dim_in, dim_out) in enumerate(zip(n_neurons[:-2], n_neurons[1:-1])):\n",
    "            layer = nn.Linear(dim_in, dim_out).double()\n",
    "            torch.nn.init.xavier_uniform_(layer.weight)\n",
    "            torch.nn.init.zeros_(layer.bias)\n",
    "            exec('self.layer{} = layer'.format(i + 1))\n",
    "\n",
    "        self.output = nn.Linear(n_neurons[-2], n_neurons[-1]).double()\n",
    "        torch.nn.init.xavier_uniform_(self.output.weight)\n",
    "        torch.nn.init.zeros_(self.output.bias)\n",
    "\n",
    "    def forward(self, observation: torch.Tensor):\n",
    "        x = observation\n",
    "        for i in range(self.num_layers):\n",
    "            x = eval('torch.tanh(self.layer{}(x))'.format(i + 1))\n",
    "        return self.output(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "####     Training for the 'Chart-Pole' Environment     #####\n",
    "############################################################\n",
    "\n",
    "Tensor = torch.DoubleTensor\n",
    "torch.set_default_tensor_type(Tensor)\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "config = {\n",
    "    'dim_obs': 4,  # Q network input\n",
    "    'dim_action': 2,  # Q network output\n",
    "    'dims_hidden_neurons': (64, 64),  # Q network hidden\n",
    "    'lr': 0.0003,  # learning rate, default = 0.0005\n",
    "    'C': 60,  # copy steps\n",
    "    'discount': 0.99,  # discount factor\n",
    "    'batch_size': 64,\n",
    "    'replay_buffer_size': 100000,\n",
    "    'eps_min': 0.01,\n",
    "    'eps_max': 1.0,\n",
    "    'eps_len': 4000,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "dqn = DQN(config)\n",
    "buffer = ReplayBuffer(config)\n",
    "train_writer = SummaryWriter(log_dir='tensorboard/dqn_{date:%Y-%m-%d_%H:%M:%S}'.format(\n",
    "                             date=datetime.datetime.now()))\n",
    "\n",
    "steps = 0  # total number of steps\n",
    "for i_episode in range(500):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    t = 0  # time steps within each episode\n",
    "    ret = 0.  # episodic return\n",
    "    while done is False:\n",
    "        env.render()  # render to screen\n",
    "\n",
    "        obs = torch.tensor(env.state)  # observe the environment state\n",
    "\n",
    "        action = dqn.act_operate(obs[None, :])  # take action\n",
    "\n",
    "        next_obs, reward, done, info = env.step(action)  # environment advance to next step\n",
    "\n",
    "        buffer.append_memory(obs=obs,  # put the transition to memory\n",
    "                             action=torch.from_numpy(np.array([action])),\n",
    "                             reward=torch.from_numpy(np.array([reward])),\n",
    "                             next_obs=torch.from_numpy(next_obs),\n",
    "                             done=done)\n",
    "\n",
    "        dqn.update(buffer)  # agent learn\n",
    "\n",
    "        t += 1\n",
    "        steps += 1\n",
    "        ret += reward  # update episodic return\n",
    "        if done:\n",
    "            print(\"Episode {} finished after {} timesteps\".format(i_episode, t+1))\n",
    "        train_writer.add_scalar('Performance/episodic_return', ret, i_episode)  # plot\n",
    "\n",
    "env.close()\n",
    "train_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 finished after 201 timesteps\n",
      "Episode 1 finished after 201 timesteps\n",
      "Episode 2 finished after 201 timesteps\n",
      "Episode 3 finished after 201 timesteps\n",
      "Episode 4 finished after 201 timesteps\n",
      "Episode 5 finished after 201 timesteps\n",
      "Episode 6 finished after 201 timesteps\n",
      "Episode 7 finished after 201 timesteps\n",
      "Episode 8 finished after 201 timesteps\n",
      "Episode 9 finished after 201 timesteps\n",
      "Episode 10 finished after 201 timesteps\n",
      "Episode 11 finished after 201 timesteps\n",
      "Episode 12 finished after 201 timesteps\n",
      "Episode 13 finished after 201 timesteps\n",
      "Episode 14 finished after 201 timesteps\n",
      "Episode 15 finished after 201 timesteps\n",
      "Episode 16 finished after 201 timesteps\n",
      "Episode 17 finished after 201 timesteps\n",
      "Episode 18 finished after 201 timesteps\n",
      "Episode 19 finished after 201 timesteps\n",
      "Episode 20 finished after 201 timesteps\n",
      "Episode 21 finished after 201 timesteps\n",
      "Episode 22 finished after 201 timesteps\n",
      "Episode 23 finished after 201 timesteps\n",
      "Episode 24 finished after 201 timesteps\n",
      "Episode 25 finished after 201 timesteps\n",
      "Episode 26 finished after 201 timesteps\n",
      "Episode 27 finished after 186 timesteps\n",
      "Episode 28 finished after 186 timesteps\n",
      "Episode 29 finished after 201 timesteps\n",
      "Episode 30 finished after 201 timesteps\n",
      "Episode 31 finished after 201 timesteps\n",
      "Episode 32 finished after 201 timesteps\n",
      "Episode 33 finished after 201 timesteps\n",
      "Episode 34 finished after 201 timesteps\n",
      "Episode 35 finished after 160 timesteps\n",
      "Episode 36 finished after 201 timesteps\n",
      "Episode 37 finished after 201 timesteps\n",
      "Episode 38 finished after 134 timesteps\n",
      "Episode 39 finished after 201 timesteps\n",
      "Episode 40 finished after 201 timesteps\n",
      "Episode 41 finished after 201 timesteps\n",
      "Episode 42 finished after 201 timesteps\n",
      "Episode 43 finished after 156 timesteps\n",
      "Episode 44 finished after 189 timesteps\n",
      "Episode 45 finished after 187 timesteps\n",
      "Episode 46 finished after 185 timesteps\n",
      "Episode 47 finished after 106 timesteps\n",
      "Episode 48 finished after 201 timesteps\n",
      "Episode 49 finished after 128 timesteps\n",
      "Episode 50 finished after 119 timesteps\n",
      "Episode 51 finished after 201 timesteps\n",
      "Episode 52 finished after 201 timesteps\n",
      "Episode 53 finished after 186 timesteps\n",
      "Episode 54 finished after 201 timesteps\n",
      "Episode 55 finished after 201 timesteps\n",
      "Episode 56 finished after 188 timesteps\n",
      "Episode 57 finished after 201 timesteps\n",
      "Episode 58 finished after 155 timesteps\n",
      "Episode 59 finished after 157 timesteps\n",
      "Episode 60 finished after 201 timesteps\n",
      "Episode 61 finished after 170 timesteps\n",
      "Episode 62 finished after 137 timesteps\n",
      "Episode 63 finished after 201 timesteps\n",
      "Episode 64 finished after 151 timesteps\n",
      "Episode 65 finished after 170 timesteps\n",
      "Episode 66 finished after 192 timesteps\n",
      "Episode 67 finished after 201 timesteps\n",
      "Episode 68 finished after 167 timesteps\n",
      "Episode 69 finished after 126 timesteps\n",
      "Episode 70 finished after 191 timesteps\n",
      "Episode 71 finished after 118 timesteps\n",
      "Episode 72 finished after 118 timesteps\n",
      "Episode 73 finished after 119 timesteps\n",
      "Episode 74 finished after 162 timesteps\n",
      "Episode 75 finished after 122 timesteps\n",
      "Episode 76 finished after 122 timesteps\n",
      "Episode 77 finished after 194 timesteps\n",
      "Episode 78 finished after 120 timesteps\n",
      "Episode 79 finished after 149 timesteps\n",
      "Episode 80 finished after 123 timesteps\n",
      "Episode 81 finished after 189 timesteps\n",
      "Episode 82 finished after 185 timesteps\n",
      "Episode 83 finished after 172 timesteps\n",
      "Episode 84 finished after 87 timesteps\n",
      "Episode 85 finished after 195 timesteps\n",
      "Episode 86 finished after 161 timesteps\n",
      "Episode 87 finished after 155 timesteps\n",
      "Episode 88 finished after 160 timesteps\n",
      "Episode 89 finished after 195 timesteps\n",
      "Episode 90 finished after 201 timesteps\n",
      "Episode 91 finished after 102 timesteps\n",
      "Episode 92 finished after 177 timesteps\n",
      "Episode 93 finished after 147 timesteps\n",
      "Episode 94 finished after 108 timesteps\n",
      "Episode 95 finished after 112 timesteps\n",
      "Episode 96 finished after 122 timesteps\n",
      "Episode 97 finished after 201 timesteps\n",
      "Episode 98 finished after 154 timesteps\n",
      "Episode 99 finished after 155 timesteps\n",
      "Episode 100 finished after 119 timesteps\n",
      "Episode 101 finished after 111 timesteps\n",
      "Episode 102 finished after 121 timesteps\n",
      "Episode 103 finished after 175 timesteps\n",
      "Episode 104 finished after 201 timesteps\n",
      "Episode 105 finished after 122 timesteps\n",
      "Episode 106 finished after 201 timesteps\n",
      "Episode 107 finished after 118 timesteps\n",
      "Episode 108 finished after 173 timesteps\n",
      "Episode 109 finished after 175 timesteps\n",
      "Episode 110 finished after 189 timesteps\n",
      "Episode 111 finished after 177 timesteps\n",
      "Episode 112 finished after 122 timesteps\n",
      "Episode 113 finished after 152 timesteps\n",
      "Episode 114 finished after 119 timesteps\n",
      "Episode 115 finished after 117 timesteps\n",
      "Episode 116 finished after 140 timesteps\n",
      "Episode 117 finished after 201 timesteps\n",
      "Episode 118 finished after 170 timesteps\n",
      "Episode 119 finished after 201 timesteps\n",
      "Episode 120 finished after 201 timesteps\n",
      "Episode 121 finished after 139 timesteps\n",
      "Episode 122 finished after 201 timesteps\n",
      "Episode 123 finished after 116 timesteps\n",
      "Episode 124 finished after 192 timesteps\n",
      "Episode 125 finished after 201 timesteps\n",
      "Episode 126 finished after 121 timesteps\n",
      "Episode 127 finished after 180 timesteps\n",
      "Episode 128 finished after 123 timesteps\n",
      "Episode 129 finished after 179 timesteps\n",
      "Episode 130 finished after 201 timesteps\n",
      "Episode 131 finished after 127 timesteps\n",
      "Episode 132 finished after 178 timesteps\n",
      "Episode 133 finished after 92 timesteps\n",
      "Episode 134 finished after 177 timesteps\n",
      "Episode 135 finished after 145 timesteps\n",
      "Episode 136 finished after 181 timesteps\n",
      "Episode 137 finished after 201 timesteps\n",
      "Episode 138 finished after 201 timesteps\n",
      "Episode 139 finished after 146 timesteps\n",
      "Episode 140 finished after 201 timesteps\n",
      "Episode 141 finished after 91 timesteps\n",
      "Episode 142 finished after 143 timesteps\n",
      "Episode 143 finished after 162 timesteps\n",
      "Episode 144 finished after 159 timesteps\n",
      "Episode 145 finished after 174 timesteps\n",
      "Episode 146 finished after 178 timesteps\n",
      "Episode 147 finished after 173 timesteps\n",
      "Episode 148 finished after 165 timesteps\n",
      "Episode 149 finished after 201 timesteps\n",
      "Episode 150 finished after 150 timesteps\n",
      "Episode 151 finished after 201 timesteps\n",
      "Episode 152 finished after 201 timesteps\n",
      "Episode 153 finished after 201 timesteps\n",
      "Episode 154 finished after 142 timesteps\n",
      "Episode 155 finished after 167 timesteps\n",
      "Episode 156 finished after 201 timesteps\n",
      "Episode 157 finished after 140 timesteps\n",
      "Episode 158 finished after 201 timesteps\n",
      "Episode 159 finished after 201 timesteps\n",
      "Episode 160 finished after 113 timesteps\n",
      "Episode 161 finished after 199 timesteps\n",
      "Episode 162 finished after 104 timesteps\n",
      "Episode 163 finished after 163 timesteps\n",
      "Episode 164 finished after 154 timesteps\n",
      "Episode 165 finished after 166 timesteps\n",
      "Episode 166 finished after 159 timesteps\n",
      "Episode 167 finished after 201 timesteps\n",
      "Episode 168 finished after 201 timesteps\n",
      "Episode 169 finished after 145 timesteps\n",
      "Episode 170 finished after 159 timesteps\n",
      "Episode 171 finished after 201 timesteps\n",
      "Episode 172 finished after 196 timesteps\n",
      "Episode 173 finished after 201 timesteps\n",
      "Episode 174 finished after 201 timesteps\n",
      "Episode 175 finished after 129 timesteps\n",
      "Episode 176 finished after 185 timesteps\n",
      "Episode 177 finished after 118 timesteps\n",
      "Episode 178 finished after 201 timesteps\n",
      "Episode 179 finished after 130 timesteps\n",
      "Episode 180 finished after 166 timesteps\n",
      "Episode 181 finished after 121 timesteps\n",
      "Episode 182 finished after 183 timesteps\n",
      "Episode 183 finished after 141 timesteps\n",
      "Episode 184 finished after 144 timesteps\n",
      "Episode 185 finished after 122 timesteps\n",
      "Episode 186 finished after 130 timesteps\n",
      "Episode 187 finished after 150 timesteps\n",
      "Episode 188 finished after 171 timesteps\n",
      "Episode 189 finished after 191 timesteps\n",
      "Episode 190 finished after 153 timesteps\n",
      "Episode 191 finished after 163 timesteps\n",
      "Episode 192 finished after 151 timesteps\n",
      "Episode 193 finished after 201 timesteps\n",
      "Episode 194 finished after 157 timesteps\n",
      "Episode 195 finished after 157 timesteps\n",
      "Episode 196 finished after 201 timesteps\n",
      "Episode 197 finished after 146 timesteps\n",
      "Episode 198 finished after 167 timesteps\n",
      "Episode 199 finished after 150 timesteps\n",
      "Episode 200 finished after 181 timesteps\n",
      "Episode 201 finished after 169 timesteps\n",
      "Episode 202 finished after 164 timesteps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 203 finished after 166 timesteps\n",
      "Episode 204 finished after 146 timesteps\n",
      "Episode 205 finished after 170 timesteps\n",
      "Episode 206 finished after 169 timesteps\n",
      "Episode 207 finished after 201 timesteps\n",
      "Episode 208 finished after 150 timesteps\n",
      "Episode 209 finished after 161 timesteps\n",
      "Episode 210 finished after 168 timesteps\n",
      "Episode 211 finished after 194 timesteps\n",
      "Episode 212 finished after 201 timesteps\n",
      "Episode 213 finished after 201 timesteps\n",
      "Episode 214 finished after 201 timesteps\n",
      "Episode 215 finished after 201 timesteps\n",
      "Episode 216 finished after 201 timesteps\n",
      "Episode 217 finished after 117 timesteps\n",
      "Episode 218 finished after 196 timesteps\n",
      "Episode 219 finished after 201 timesteps\n",
      "Episode 220 finished after 141 timesteps\n",
      "Episode 221 finished after 131 timesteps\n",
      "Episode 222 finished after 116 timesteps\n",
      "Episode 223 finished after 192 timesteps\n",
      "Episode 224 finished after 185 timesteps\n",
      "Episode 225 finished after 171 timesteps\n",
      "Episode 226 finished after 132 timesteps\n",
      "Episode 227 finished after 166 timesteps\n",
      "Episode 228 finished after 201 timesteps\n",
      "Episode 229 finished after 201 timesteps\n",
      "Episode 230 finished after 174 timesteps\n",
      "Episode 231 finished after 91 timesteps\n",
      "Episode 232 finished after 169 timesteps\n",
      "Episode 233 finished after 121 timesteps\n",
      "Episode 234 finished after 152 timesteps\n",
      "Episode 235 finished after 155 timesteps\n",
      "Episode 236 finished after 152 timesteps\n",
      "Episode 237 finished after 127 timesteps\n",
      "Episode 238 finished after 128 timesteps\n",
      "Episode 239 finished after 126 timesteps\n",
      "Episode 240 finished after 114 timesteps\n",
      "Episode 241 finished after 137 timesteps\n",
      "Episode 242 finished after 201 timesteps\n",
      "Episode 243 finished after 169 timesteps\n",
      "Episode 244 finished after 121 timesteps\n",
      "Episode 245 finished after 161 timesteps\n",
      "Episode 246 finished after 201 timesteps\n",
      "Episode 247 finished after 194 timesteps\n",
      "Episode 248 finished after 180 timesteps\n",
      "Episode 249 finished after 184 timesteps\n",
      "Episode 250 finished after 189 timesteps\n",
      "Episode 251 finished after 169 timesteps\n",
      "Episode 252 finished after 160 timesteps\n",
      "Episode 253 finished after 197 timesteps\n",
      "Episode 254 finished after 172 timesteps\n",
      "Episode 255 finished after 110 timesteps\n",
      "Episode 256 finished after 169 timesteps\n",
      "Episode 257 finished after 149 timesteps\n",
      "Episode 258 finished after 135 timesteps\n",
      "Episode 259 finished after 158 timesteps\n",
      "Episode 260 finished after 173 timesteps\n",
      "Episode 261 finished after 180 timesteps\n",
      "Episode 262 finished after 158 timesteps\n",
      "Episode 263 finished after 125 timesteps\n",
      "Episode 264 finished after 195 timesteps\n",
      "Episode 265 finished after 152 timesteps\n",
      "Episode 266 finished after 148 timesteps\n",
      "Episode 267 finished after 160 timesteps\n",
      "Episode 268 finished after 124 timesteps\n",
      "Episode 269 finished after 150 timesteps\n",
      "Episode 270 finished after 177 timesteps\n",
      "Episode 271 finished after 119 timesteps\n",
      "Episode 272 finished after 132 timesteps\n",
      "Episode 273 finished after 106 timesteps\n",
      "Episode 274 finished after 201 timesteps\n",
      "Episode 275 finished after 119 timesteps\n",
      "Episode 276 finished after 123 timesteps\n",
      "Episode 277 finished after 176 timesteps\n",
      "Episode 278 finished after 139 timesteps\n",
      "Episode 279 finished after 96 timesteps\n",
      "Episode 280 finished after 137 timesteps\n",
      "Episode 281 finished after 160 timesteps\n",
      "Episode 282 finished after 94 timesteps\n",
      "Episode 283 finished after 130 timesteps\n",
      "Episode 284 finished after 167 timesteps\n",
      "Episode 285 finished after 201 timesteps\n",
      "Episode 286 finished after 174 timesteps\n",
      "Episode 287 finished after 166 timesteps\n",
      "Episode 288 finished after 137 timesteps\n",
      "Episode 289 finished after 180 timesteps\n",
      "Episode 290 finished after 162 timesteps\n",
      "Episode 291 finished after 168 timesteps\n",
      "Episode 292 finished after 152 timesteps\n",
      "Episode 293 finished after 162 timesteps\n",
      "Episode 294 finished after 180 timesteps\n",
      "Episode 295 finished after 156 timesteps\n",
      "Episode 296 finished after 200 timesteps\n",
      "Episode 297 finished after 177 timesteps\n",
      "Episode 298 finished after 152 timesteps\n",
      "Episode 299 finished after 169 timesteps\n",
      "Episode 300 finished after 150 timesteps\n",
      "Episode 301 finished after 162 timesteps\n",
      "Episode 302 finished after 111 timesteps\n",
      "Episode 303 finished after 128 timesteps\n",
      "Episode 304 finished after 88 timesteps\n",
      "Episode 305 finished after 201 timesteps\n",
      "Episode 306 finished after 153 timesteps\n",
      "Episode 307 finished after 201 timesteps\n",
      "Episode 308 finished after 110 timesteps\n",
      "Episode 309 finished after 120 timesteps\n",
      "Episode 310 finished after 112 timesteps\n",
      "Episode 311 finished after 158 timesteps\n",
      "Episode 312 finished after 159 timesteps\n",
      "Episode 313 finished after 94 timesteps\n",
      "Episode 314 finished after 201 timesteps\n",
      "Episode 315 finished after 146 timesteps\n",
      "Episode 316 finished after 152 timesteps\n",
      "Episode 317 finished after 186 timesteps\n",
      "Episode 318 finished after 111 timesteps\n",
      "Episode 319 finished after 160 timesteps\n",
      "Episode 320 finished after 176 timesteps\n",
      "Episode 321 finished after 127 timesteps\n",
      "Episode 322 finished after 196 timesteps\n",
      "Episode 323 finished after 129 timesteps\n",
      "Episode 324 finished after 141 timesteps\n",
      "Episode 325 finished after 117 timesteps\n",
      "Episode 326 finished after 201 timesteps\n",
      "Episode 327 finished after 167 timesteps\n",
      "Episode 328 finished after 142 timesteps\n",
      "Episode 329 finished after 201 timesteps\n",
      "Episode 330 finished after 148 timesteps\n",
      "Episode 331 finished after 176 timesteps\n",
      "Episode 332 finished after 133 timesteps\n",
      "Episode 333 finished after 157 timesteps\n",
      "Episode 334 finished after 151 timesteps\n",
      "Episode 335 finished after 118 timesteps\n",
      "Episode 336 finished after 165 timesteps\n",
      "Episode 337 finished after 129 timesteps\n",
      "Episode 338 finished after 201 timesteps\n",
      "Episode 339 finished after 201 timesteps\n",
      "Episode 340 finished after 194 timesteps\n",
      "Episode 341 finished after 157 timesteps\n",
      "Episode 342 finished after 201 timesteps\n",
      "Episode 343 finished after 153 timesteps\n",
      "Episode 344 finished after 183 timesteps\n",
      "Episode 345 finished after 166 timesteps\n",
      "Episode 346 finished after 109 timesteps\n",
      "Episode 347 finished after 201 timesteps\n",
      "Episode 348 finished after 188 timesteps\n",
      "Episode 349 finished after 122 timesteps\n",
      "Episode 350 finished after 170 timesteps\n",
      "Episode 351 finished after 122 timesteps\n",
      "Episode 352 finished after 151 timesteps\n",
      "Episode 353 finished after 130 timesteps\n",
      "Episode 354 finished after 172 timesteps\n",
      "Episode 355 finished after 158 timesteps\n",
      "Episode 356 finished after 172 timesteps\n",
      "Episode 357 finished after 165 timesteps\n",
      "Episode 358 finished after 201 timesteps\n",
      "Episode 359 finished after 151 timesteps\n",
      "Episode 360 finished after 169 timesteps\n",
      "Episode 361 finished after 145 timesteps\n",
      "Episode 362 finished after 150 timesteps\n",
      "Episode 363 finished after 131 timesteps\n",
      "Episode 364 finished after 127 timesteps\n",
      "Episode 365 finished after 200 timesteps\n",
      "Episode 366 finished after 155 timesteps\n",
      "Episode 367 finished after 201 timesteps\n",
      "Episode 368 finished after 115 timesteps\n",
      "Episode 369 finished after 114 timesteps\n",
      "Episode 370 finished after 125 timesteps\n",
      "Episode 371 finished after 195 timesteps\n",
      "Episode 372 finished after 201 timesteps\n",
      "Episode 373 finished after 201 timesteps\n",
      "Episode 374 finished after 131 timesteps\n",
      "Episode 375 finished after 184 timesteps\n",
      "Episode 376 finished after 188 timesteps\n",
      "Episode 377 finished after 168 timesteps\n",
      "Episode 378 finished after 152 timesteps\n",
      "Episode 379 finished after 187 timesteps\n",
      "Episode 380 finished after 201 timesteps\n",
      "Episode 381 finished after 158 timesteps\n",
      "Episode 382 finished after 201 timesteps\n",
      "Episode 383 finished after 150 timesteps\n",
      "Episode 384 finished after 155 timesteps\n",
      "Episode 385 finished after 123 timesteps\n",
      "Episode 386 finished after 136 timesteps\n",
      "Episode 387 finished after 147 timesteps\n",
      "Episode 388 finished after 160 timesteps\n",
      "Episode 389 finished after 136 timesteps\n",
      "Episode 390 finished after 201 timesteps\n",
      "Episode 391 finished after 196 timesteps\n",
      "Episode 392 finished after 183 timesteps\n",
      "Episode 393 finished after 201 timesteps\n",
      "Episode 394 finished after 201 timesteps\n",
      "Episode 395 finished after 135 timesteps\n",
      "Episode 396 finished after 119 timesteps\n",
      "Episode 397 finished after 115 timesteps\n",
      "Episode 398 finished after 158 timesteps\n",
      "Episode 399 finished after 122 timesteps\n",
      "Episode 400 finished after 201 timesteps\n",
      "Episode 401 finished after 155 timesteps\n",
      "Episode 402 finished after 198 timesteps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 403 finished after 117 timesteps\n",
      "Episode 404 finished after 120 timesteps\n",
      "Episode 405 finished after 131 timesteps\n",
      "Episode 406 finished after 201 timesteps\n",
      "Episode 407 finished after 201 timesteps\n",
      "Episode 408 finished after 176 timesteps\n",
      "Episode 409 finished after 160 timesteps\n",
      "Episode 410 finished after 156 timesteps\n",
      "Episode 411 finished after 156 timesteps\n",
      "Episode 412 finished after 151 timesteps\n",
      "Episode 413 finished after 152 timesteps\n",
      "Episode 414 finished after 161 timesteps\n",
      "Episode 415 finished after 131 timesteps\n",
      "Episode 416 finished after 97 timesteps\n",
      "Episode 417 finished after 169 timesteps\n",
      "Episode 418 finished after 201 timesteps\n",
      "Episode 419 finished after 191 timesteps\n",
      "Episode 420 finished after 201 timesteps\n",
      "Episode 421 finished after 188 timesteps\n",
      "Episode 422 finished after 189 timesteps\n",
      "Episode 423 finished after 129 timesteps\n",
      "Episode 424 finished after 124 timesteps\n",
      "Episode 425 finished after 201 timesteps\n",
      "Episode 426 finished after 201 timesteps\n",
      "Episode 427 finished after 201 timesteps\n",
      "Episode 428 finished after 156 timesteps\n",
      "Episode 429 finished after 201 timesteps\n",
      "Episode 430 finished after 201 timesteps\n",
      "Episode 431 finished after 155 timesteps\n",
      "Episode 432 finished after 201 timesteps\n",
      "Episode 433 finished after 150 timesteps\n",
      "Episode 434 finished after 175 timesteps\n",
      "Episode 435 finished after 175 timesteps\n",
      "Episode 436 finished after 150 timesteps\n",
      "Episode 437 finished after 159 timesteps\n",
      "Episode 438 finished after 153 timesteps\n",
      "Episode 439 finished after 155 timesteps\n",
      "Episode 440 finished after 166 timesteps\n",
      "Episode 441 finished after 201 timesteps\n",
      "Episode 442 finished after 127 timesteps\n",
      "Episode 443 finished after 201 timesteps\n",
      "Episode 444 finished after 137 timesteps\n",
      "Episode 445 finished after 111 timesteps\n",
      "Episode 446 finished after 138 timesteps\n",
      "Episode 447 finished after 146 timesteps\n",
      "Episode 448 finished after 126 timesteps\n",
      "Episode 449 finished after 111 timesteps\n",
      "Episode 450 finished after 126 timesteps\n",
      "Episode 451 finished after 115 timesteps\n",
      "Episode 452 finished after 156 timesteps\n",
      "Episode 453 finished after 184 timesteps\n",
      "Episode 454 finished after 170 timesteps\n",
      "Episode 455 finished after 201 timesteps\n",
      "Episode 456 finished after 138 timesteps\n",
      "Episode 457 finished after 168 timesteps\n",
      "Episode 458 finished after 201 timesteps\n",
      "Episode 459 finished after 201 timesteps\n",
      "Episode 460 finished after 171 timesteps\n",
      "Episode 461 finished after 159 timesteps\n",
      "Episode 462 finished after 131 timesteps\n",
      "Episode 463 finished after 123 timesteps\n",
      "Episode 464 finished after 118 timesteps\n",
      "Episode 465 finished after 158 timesteps\n",
      "Episode 466 finished after 126 timesteps\n",
      "Episode 467 finished after 124 timesteps\n",
      "Episode 468 finished after 155 timesteps\n",
      "Episode 469 finished after 115 timesteps\n",
      "Episode 470 finished after 201 timesteps\n",
      "Episode 471 finished after 201 timesteps\n",
      "Episode 472 finished after 201 timesteps\n",
      "Episode 473 finished after 201 timesteps\n",
      "Episode 474 finished after 201 timesteps\n",
      "Episode 475 finished after 109 timesteps\n",
      "Episode 476 finished after 164 timesteps\n",
      "Episode 477 finished after 164 timesteps\n",
      "Episode 478 finished after 159 timesteps\n",
      "Episode 479 finished after 175 timesteps\n",
      "Episode 480 finished after 149 timesteps\n",
      "Episode 481 finished after 181 timesteps\n",
      "Episode 482 finished after 201 timesteps\n",
      "Episode 483 finished after 201 timesteps\n",
      "Episode 484 finished after 201 timesteps\n",
      "Episode 485 finished after 201 timesteps\n",
      "Episode 486 finished after 124 timesteps\n",
      "Episode 487 finished after 111 timesteps\n",
      "Episode 488 finished after 122 timesteps\n",
      "Episode 489 finished after 183 timesteps\n",
      "Episode 490 finished after 138 timesteps\n",
      "Episode 491 finished after 130 timesteps\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "####    Training for the 'MountainCar' Environment     #####\n",
    "############################################################\n",
    "\n",
    "Tensor = torch.DoubleTensor\n",
    "torch.set_default_tensor_type(Tensor)\n",
    "\n",
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "config = {\n",
    "    'dim_obs': 2,  # Q network input\n",
    "    'dim_action': 3,  # Q network output\n",
    "    'dims_hidden_neurons': (256, 256),  # Q network hidden\n",
    "    'lr': 0.005,  # learning rate, default = 0.0005\n",
    "    'C': 60,  # copy steps\n",
    "    'discount': 0.99,  # discount factor\n",
    "    'batch_size': 64,\n",
    "    'replay_buffer_size': 100000,\n",
    "    'eps_min': 0.01,\n",
    "    'eps_max': 1.0,\n",
    "    'eps_len': 4000,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "dqn = DQN(config)\n",
    "buffer = ReplayBuffer(config)\n",
    "train_writer = SummaryWriter(log_dir='tensorboard/dqn_{date:%Y-%m-%d_%H:%M:%S}'.format(\n",
    "                             date=datetime.datetime.now()))\n",
    "\n",
    "steps = 0  # total number of steps\n",
    "for i_episode in range(500):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    t = 0  # time steps within each episode\n",
    "    ret = 0.  # episodic return\n",
    "    while done is False:\n",
    "        env.render()  # render to screen\n",
    "\n",
    "        obs = torch.tensor(env.state)  # observe the environment state\n",
    "\n",
    "        action = dqn.act_operate(obs[None, :])  # take action\n",
    "\n",
    "        next_obs, reward, done, info = env.step(action)  # environment advance to next step\n",
    "\n",
    "        buffer.append_memory(obs=obs,  # put the transition to memory\n",
    "                             action=torch.from_numpy(np.array([action])),\n",
    "                             reward=torch.from_numpy(np.array([reward])),\n",
    "                             next_obs=torch.from_numpy(next_obs),\n",
    "                             done=done)\n",
    "\n",
    "        dqn.update(buffer)  # agent learn\n",
    "\n",
    "        t += 1\n",
    "        steps += 1\n",
    "        ret += reward  # update episodic return\n",
    "        if done:\n",
    "            print(\"Episode {} finished after {} timesteps\".format(i_episode, t+1))\n",
    "        train_writer.add_scalar('Performance/episodic_return', ret, i_episode)  # plot\n",
    "\n",
    "env.close()\n",
    "train_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
